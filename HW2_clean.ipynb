{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {
    "id": "609dcb62-c2f8-4c6d-9c89-63dc0148a87c"
   },
   "source": [
    "<div align=\"center\">\n",
    "\n",
    "###### Lab 2\n",
    "\n",
    "# National Tsing Hua University\n",
    "\n",
    "#### Spring 2025\n",
    "\n",
    "#### 11320IEEM 513600\n",
    "\n",
    "#### Deep Learning and Industrial Applications\n",
    "    \n",
    "## Lab 2: Predicting Heart Disease with Deep Learning\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1",
   "metadata": {
    "id": "061c22d2-eec4-40f4-866b-ccaa2d9a2963",
    "tags": []
   },
   "source": [
    "### Introduction\n",
    "\n",
    "In the realm of healthcare, early detection and accurate prediction of diseases play a crucial role in patient care and management. Heart disease remains one of the leading causes of mortality worldwide, making the development of effective diagnostic tools essential. This lab leverages deep learning to predict the presence of heart disease in patients using a subset of 14 key attributes from the Cleveland Heart Disease Database. The objective is to explore and apply deep learning techniques to distinguish between the presence and absence of heart disease based on clinical parameters.\n",
    "\n",
    "Throughout this lab, you'll engage with the following key activities:\n",
    "- Use [Pandas](https://pandas.pydata.org) to process the CSV files.\n",
    "- Use [PyTorch](https://pytorch.org) to build an Artificial Neural Network (ANN) to fit the dataset.\n",
    "- Evaluate the performance of the trained model to understand its accuracy.\n",
    "\n",
    "### Attribute Information\n",
    "\n",
    "1. age: Age of the patient in years\n",
    "2. sex: (Male/Female)\n",
    "3. cp: Chest pain type (4 types: low, medium, high, and severe)\n",
    "4. trestbps: Resting blood pressure\n",
    "5. chol: Serum cholesterol in mg/dl\n",
    "6. fbs: Fasting blood sugar > 120 mg/dl\n",
    "7. restecg: Resting electrocardiographic results (values 0,1,2)\n",
    "8. thalach: Maximum heart rate achieved\n",
    "9. exang: Exercise induced angina\n",
    "10. oldpeak: Oldpeak = ST depression induced by exercise relative to rest\n",
    "11. slope: The slope of the peak exercise ST segment\n",
    "12. ca: Number of major vessels (0-3) colored by fluoroscopy\n",
    "13. thal: 3 = normal; 6 = fixed defect; 7 = reversible defect\n",
    "14. target: target have disease or not (1=yes, 0=no)\n",
    "\n",
    "### References\n",
    "- [UCI Heart Disease Data](https://www.kaggle.com/datasets/redwankarimsony/heart-disease-data) for the dataset we use in this lab.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2",
   "metadata": {
    "id": "ad594fc8-4989-40f3-b124-4550fe7df386"
   },
   "source": [
    "## A. Checking and Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 423
    },
    "id": "42a3eafd-cbcd-4c56-82cb-83a0bfa2399e",
    "outputId": "bf3368a5-76b7-465f-d33f-6be8af29c0ba"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('heart_dataset_train_all.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "34241797-60f0-4818-a44b-f5379948d621",
    "outputId": "a9f950ad-dfa3-4d0a-c0f3-03b4c610729a"
   },
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "026585db-a6d8-4062-85de-e3a7eaebed72",
    "outputId": "c9558ac8-afbb-4b4e-b6a9-64fc69c1d595"
   },
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 522
    },
    "id": "69031e6d-0fb5-49d9-b723-a0d1fee08c3c",
    "outputId": "9aad869e-b8c3-49b6-ceb6-68cfcdd813e2"
   },
   "outputs": [],
   "source": [
    "# checking for null values\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {
    "id": "cb3090f8-2cfa-4f56-8aa5-cf954bb19932"
   },
   "outputs": [],
   "source": [
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "38aadbee-d68f-4ae0-b842-b40800b0cac9",
    "outputId": "be32805d-14ff-4bc3-c7fb-55dc71898484"
   },
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 423
    },
    "id": "26a69fd5-3534-4d8e-b59a-6778bf47a479",
    "outputId": "d8c16aaa-9b1a-4cce-9e8c-7fff182fbb7b"
   },
   "outputs": [],
   "source": [
    "# Mapping 'sex' descriptions to numbers\n",
    "sex_description = {\n",
    "    'Male': 0,\n",
    "    'Female': 1,\n",
    "}\n",
    "df.loc[:, 'sex'] = df['sex'].map(sex_description)\n",
    "\n",
    "# Mapping 'cp' (chest pain) descriptions to numbers\n",
    "pain_description = {\n",
    "    'low': 0,\n",
    "    'medium': 1,\n",
    "    'high': 2,\n",
    "    'severe': 3\n",
    "}\n",
    "df.loc[:, 'cp'] = df['cp'].map(pain_description)\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 320
    },
    "id": "051108c6-7011-4187-9e36-bd2944a019ca",
    "outputId": "1cd0eb1d-95b6-4522-c0cc-559db24e52d7"
   },
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 508
    },
    "id": "8b999df5-09a1-4ce2-b068-f1afba448ff8",
    "outputId": "ce759b35-cf38-4db1-dc90-79c0e16dac9d"
   },
   "outputs": [],
   "source": [
    "df.corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12",
   "metadata": {
    "id": "8ce7a0c5-76d6-4863-ba61-0544a220962a"
   },
   "source": [
    "#### Converting the DataFrame to a NumPy Array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5735baad-2db8-4306-aa4c-7788d2b49621",
    "outputId": "086714f2-5cff-498f-b985-8296aeba76ac"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "np_data = df.values\n",
    "np_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {
    "id": "29b8e189-7f39-435a-8038-39098b147325"
   },
   "outputs": [],
   "source": [
    "split_point = int(np_data.shape[0]*0.7)\n",
    "\n",
    "np.random.shuffle(np_data)\n",
    "\n",
    "x_train = np_data[:split_point, :13]\n",
    "y_train = np_data[:split_point, 13]\n",
    "x_val = np_data[split_point:, :13]\n",
    "y_val = np_data[split_point:, 13]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fedb56d7-1665-4c90-9697-b86cab43f300",
    "outputId": "db2137b3-7ce5-44f7-ecaa-2e8be1c1dd51"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "# Convert to PyTorch tensors\n",
    "x_train = np.array(x_train, dtype=float)\n",
    "x_train = torch.from_numpy(x_train).float()\n",
    "y_train = np.array(y_train, dtype=int)\n",
    "y_train = torch.from_numpy(y_train).long()\n",
    "\n",
    "x_val = np.array(x_val, dtype=float)\n",
    "x_val = torch.from_numpy(x_val).float()\n",
    "y_val = np.array(y_val, dtype=int)\n",
    "y_val = torch.from_numpy(y_val).long()\n",
    "\n",
    "batch_size = 32\n",
    "\n",
    "# Create datasets\n",
    "train_dataset = TensorDataset(x_train, y_train)\n",
    "val_dataset = TensorDataset(x_val, y_val)\n",
    "\n",
    "# Create dataloaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "print(f'Number of samples in train and validation are {len(train_loader.dataset)} and {len(val_loader.dataset)}.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16",
   "metadata": {
    "id": "8ffc26b9-6044-41e9-93e2-7dc6250dbd27"
   },
   "source": [
    "## B. Defining Neural Networks\n",
    "\n",
    "In PyTorch, we can use **class** to define our custom neural network architectures by subclassing the `nn.Module` class. This gives our neural network all the functionality it needs to work with PyTorch's other utilities and keeps our implementation organized.\n",
    "\n",
    "- Neural networks are defined by subclassing `nn.Module`.\n",
    "- The layers of the neural network are initialized in the `__init__` method.\n",
    "- The forward pass operations on input data are defined in the `forward` method.\n",
    "\n",
    "It's worth noting that while we only define the forward pass, PyTorch will automatically derive the backward pass for us, which is used during training to update the model's weights.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {
    "id": "77975746-a7a7-4676-9527-57674cd98c0f"
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class Model(nn.Module):\n",
    "    def __init__(self, hidden_units=256):\n",
    "        super().__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(13, hidden_units),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_units, hidden_units),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_units, 2)\n",
    "        ).cuda()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18",
   "metadata": {
    "id": "cbb8b5b0-0ec0-406c-a42e-048aa00e05aa"
   },
   "source": [
    "## C. Training the Neural Network & Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3602ae7d-4034-4c49-b221-0c12a5824b18",
    "outputId": "bcfa5296-1d78-4185-b6ef-0c148cdd65c5"
   },
   "outputs": [],
   "source": [
    "# Check your GPU status.\n",
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20",
   "metadata": {
    "id": "D-YWvduD7m50"
   },
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR, StepLR\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "hidden_unit_options = [64, 128, 256]\n",
    "learning_rate_options = [0.01, 0.001, 0.0001]\n",
    "results = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21",
   "metadata": {
    "id": "f49735d7-466f-4037-8078-172f03dffd8d"
   },
   "outputs": [],
   "source": [
    "test_data = pd.read_csv('heart_dataset_test.csv')\n",
    "test_data = test_data.values\n",
    "#test_data.shape\n",
    "#test_data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22",
   "metadata": {
    "id": "14d4be20-f64f-421d-8971-e1e47873aef8"
   },
   "outputs": [],
   "source": [
    "# Convert to PyTorch tensors\n",
    "x_test = torch.from_numpy(test_data[:, :13]).float()\n",
    "y_test = torch.from_numpy(test_data[:, 13]).long()\n",
    "\n",
    "# Create datasets\n",
    "test_dataset = TensorDataset(x_test, y_test)\n",
    "\n",
    "# Create dataloaders\n",
    "test_loader = DataLoader(test_dataset, batch_size=1, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23",
   "metadata": {
    "id": "4bcf8580-42ee-4ee7-ad15-9f080cc57a33"
   },
   "outputs": [],
   "source": [
    "# Set the model to evaluation mode\n",
    "def evaluate_on_test(model, test_loader, criterion):\n",
    "  model.eval()\n",
    "\n",
    "  test_correct = 0\n",
    "  test_total = 0\n",
    "  total_loss = 0.0\n",
    "\n",
    "  with torch.no_grad():\n",
    "    for features, labels in test_loader:\n",
    "        features = features.cuda()\n",
    "        labels = labels.cuda()\n",
    "\n",
    "        outputs = model(features)\n",
    "        loss = criterion(outputs, labels)\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        predicted = outputs.argmax(-1)\n",
    "        test_correct += (predicted == labels).sum().item()\n",
    "        test_total += labels.size(0)\n",
    "\n",
    "  avg_loss = total_loss / len(test_loader)\n",
    "  accuracy = 100. * test_correct / test_total\n",
    "  return avg_loss, accuracy\n",
    "\n",
    "#print(f'Test accuracy is {100. * test_correct / test_total}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "caf264c074124d5894d5c6ac13330332",
      "204c20074df94aa4990ffdb2b5ec1128",
      "09b38163aa104584bb44568197d67dbf",
      "c0ac76bccbd6465fbf5cfc0844d47e35",
      "f685ae7863ac4f8b97bad827beb5f45f",
      "6876721825954c4c9b260a406d2ceeda",
      "f0db5833b4dc4202bedd7d989ac03ed1",
      "672b7e01803e46eb97279103957ac0c2",
      "f6f47b4279384ed7ab02a7f0d0a3cb98",
      "0e15579e3dea4da6997303c4dce49e7d",
      "ec0e0e4dc6bf44b191106ef675878c00",
      "53efffdfea3b4dcf8cd8e2f5d4be1d0a",
      "b87b8bf690c84f86ba559dee65abd26b",
      "f80b6389217446e3b202fa8dea592166",
      "25c4fcaf1a5948c392326a10ee1ead35",
      "dee284b0e1f74a2fa7a583bd6d6f1022",
      "ac6454cbf5cf400cb66f041e34e8536e",
      "4b2dc23deee4421db7f390647847c4b3",
      "b4a55b0657514309929a4ac352e8434f",
      "94b4151ac71844ae805fa349b43c5682",
      "6cad723786e74c70bbb9b98a3bd6de38",
      "049bfc83f1a641829d23cc2b098759d2",
      "f5bd4081865e485a934d17ddee3644ea",
      "b88c36c74ee5416cb6423006c936c47d",
      "9f8cf7ba1968499aaa2c33b01db579ff",
      "888d3d22d9ec4e90b7e17600facf8c8d",
      "958f66b4c04945c8ada819e679aca65d",
      "d09f997c94aa4919aecfd610ef74082d",
      "b977fb8c32204fd28ce3fc01d41852b0",
      "d72794ae38a246b9a4875c8811118298",
      "a3496f9cca1445d883e66d8575fa541c",
      "2dbda5826d8345c1a472aa986b1795a0",
      "4671d99f216b4f6b8e27414cd54ef372",
      "163e64eacd14423fade47e5d95e401bf",
      "28eea40cc8284d1583c44b7782f46a94",
      "602cc166f1d942d68bec981f1e0b83b4",
      "09317b8a0a4b444cbbafe9a27960cae0",
      "1ad8ca65a2db454892fa93ce48dd31ff",
      "91484a2f15c84d95bf0b4a693c41a90f",
      "d6626bafbcd744fda2a4c58459c20dc9",
      "891e95c3a85447c7896be788c32098cb",
      "985d8331a8e74275af06541e1f700291",
      "103c423832534caba2eba4461f6671bd",
      "2fabe6e42b4a460a903d2d7e06a46fc0",
      "984cda2e76c145ceaab832cb7f9c5bb6",
      "687510413e854ec282d683f81b1b963e",
      "12637edf173c4e71ae91a2c5aa463d90",
      "2719ad6a52fe4a75a620862f64766500",
      "efaaf698dd5d4e0b99ebb85fc7c56d58",
      "917414644b1849cea74eb0d59524f14c",
      "9c5bc4cd981c43c7bcbac20f3452d45a",
      "820dea2802d64b028867934f65cfee53",
      "8814e710a3844a96aebdae2a4fcaf224",
      "fb066ea25d044d20a7b5ff30bca8709b",
      "3db004b8807b4136bcab28b4e4f306e7",
      "97e19baa3fbb4d02822558521fd24062",
      "7bda79e2a3944d79b09861588d526fe5",
      "d0a4fc23a5834d24b52ff728400c775e",
      "9c782f3a86714fa59844cfdf2af1afcd",
      "175b96bd63d84d7eaf956c89c5dfd706",
      "16b4f7cfb2cf469a90e56eab3a17e887",
      "39d7578dc5e94ab292dc3b00b25549e1",
      "ce4e99f0aeac42b7a9fe817bc4a8e303",
      "999be68f9aa145b0961565ca1be7c573",
      "0d6d46faecc1448c837834c0350044c3",
      "4a6c7a9177dc4c7fa4aaaa355e7d3702",
      "f4ce4049244a4129bef564baa45b1aeb",
      "4b43d8b991f648a98b59bab97d2e8266",
      "a9c4785fb04c4b17b07629ddca65eb79",
      "3cf690e24c134e498dbc13c8970ebeab",
      "a1857611d32947bea51cf83697d4479e",
      "ad9a984636be40029054fd3b6f7f7db9",
      "2917e6f2d5bf4a01bf78be05071cf540",
      "f496a1c5bc7649d1a4032ef7ccd212aa",
      "522195db12eb446a9292197bb8185d10",
      "4b7010627922435180b8b722ceb9d440",
      "bc1eecd0b104460da83fc31bf196606a",
      "ae718d528f7945b8ad993d5dfb96215c",
      "1f4f4e526d76484180f72571786fffd5",
      "83907dd0e2ac4565833a5cc7e306f01c",
      "2f575cb4e2c244cca1a8df6bc37237ee",
      "cb7eaf7f93de43179099a27c62a8e3e1",
      "b8a7f62b97dc41409a8b1e9281f7a5df",
      "fe1d0ddc60c14510971288bfb84d619f",
      "91fb456e8f4c40d7a3bd738851615f45",
      "dc19896f3587442e9a217c93ff4c4f2a",
      "fda60d3b2d7b4c9e89825570fe79488c",
      "384ec701edcf41fb8a8962bb2061ef4e",
      "38e978cbcbcc48be9dff139610423ce8",
      "1b02c3388c65416980a54bf86e952929",
      "b4c192c1b40848d8a05d3627d80f39d5",
      "e53fd84ebe194d088232f2dd68814bef",
      "9c35f94f3c8f4c80ac6debab99b662d5",
      "b0992472ac1a40459317224ce0014198",
      "f1bad7d374bc43f19e594a5a275522ec",
      "79d8eb6ee9e94ce89c96fe55f8d4db0b",
      "cf716b9e16814a178195dc1c285774a2",
      "6137f7bb26964156a444ee8835f3e941",
      "7bfa5da6f84e43e69766234a8a7fc05c"
     ]
    },
    "id": "f73a5c35-c15d-49bb-8a33-a7f017159499",
    "outputId": "aa12b6cc-963c-42f0-f9bb-08cc0d82f30d"
   },
   "outputs": [],
   "source": [
    "for hidden_units in hidden_unit_options:\n",
    "  for learning_rate in learning_rate_options:\n",
    "    print(f\"Training with hidden_units={hidden_units}, learning_rate={learning_rate}\")\n",
    "\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "    train_accuracies = []\n",
    "    val_accuracies = []\n",
    "\n",
    "    epochs = 100\n",
    "\n",
    "    model = Model(hidden_units=hidden_units)\n",
    "    # print(model)\n",
    "\n",
    "    best_val_loss = float('inf')\n",
    "    best_val_acc = -1\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()  #適用於分類問題\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    lr_scheduler = CosineAnnealingLR(optimizer, T_max=epochs, eta_min=0)  #學習率最低降到0\n",
    "\n",
    "    for epoch in tqdm(range(epochs)):\n",
    "        # Training\n",
    "        model.train()  #設定模型為「訓練模式」\n",
    "        total_loss = 0.0\n",
    "        train_correct = 0\n",
    "        total_train_samples = 0\n",
    "\n",
    "        for features, labels in train_loader:\n",
    "            features = features.cuda()\n",
    "            labels = labels.cuda()\n",
    "\n",
    "            outputs = model(features)\n",
    "\n",
    "            loss = criterion(outputs, labels)\n",
    "            total_loss += loss.item()\n",
    "\n",
    "            optimizer.zero_grad()  #清空前一次的梯度\n",
    "            loss.backward()  #計算目前 loss 的梯度\n",
    "            optimizer.step()  #根據梯度更新參數\n",
    "\n",
    "            train_predicted = outputs.argmax(-1)  #找出預測機率最高的類別\n",
    "            train_correct += (train_predicted == labels).sum().item()\n",
    "            total_train_samples += labels.size(0)\n",
    "\n",
    "        # Learning rate update\n",
    "        lr_scheduler.step()  #每個 epoch 結束後，根據餘弦退火計算新學習率\n",
    "\n",
    "        avg_train_loss = total_loss / len(train_loader)  #平均損失 = 所有 batch 損失總和 / batch 數\n",
    "        train_accuracy = 100. * train_correct / total_train_samples  #準確率 = 正確數量 / 全部訓練資料數量\n",
    "\n",
    "        # Validation\n",
    "        model.eval()  #評估模式會關閉像是Dropout或BatchNorm的訓練特性\n",
    "        total_val_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        with torch.no_grad():  #停用梯度運算\n",
    "            for features, labels in val_loader:  #驗證資料迴圈\n",
    "                features = features.cuda()\n",
    "                labels = labels.cuda()\n",
    "\n",
    "                outputs = model(features)\n",
    "\n",
    "                loss = criterion(outputs, labels)\n",
    "                total_val_loss += loss.item()\n",
    "\n",
    "                predicted = outputs.argmax(-1)\n",
    "                correct += (predicted == labels).sum().item()\n",
    "                total += labels.size(0)  #計算總驗證樣本數\n",
    "\n",
    "        avg_val_loss = total_val_loss / len(val_loader)\n",
    "        val_accuracy = 100. * correct / total\n",
    "\n",
    "        # Checkpoint\n",
    "        if avg_val_loss < best_val_loss:\n",
    "            best_val_loss = avg_val_loss\n",
    "\n",
    "        if val_accuracy > best_val_acc:\n",
    "            best_val_acc = val_accuracy\n",
    "            torch.save(model.state_dict(), 'model_classification.pth')\n",
    "\n",
    "        print(f'Epoch {epoch+1}/{epochs}, Train loss: {avg_train_loss:.4f}, Train acc: {train_accuracy:.4f}%, Val loss: {avg_val_loss:.4f}, Val acc: {val_accuracy:.4f}%, Best Val loss: {best_val_loss:.4f} Best Val acc: {best_val_acc:.2f}%')\n",
    "\n",
    "        # Store performance\n",
    "        train_losses.append(avg_train_loss)\n",
    "        train_accuracies.append(train_accuracy)\n",
    "        val_losses.append(avg_val_loss)\n",
    "        val_accuracies.append(val_accuracy)\n",
    "\n",
    "    model.load_state_dict(torch.load('model_classification.pth'))\n",
    "    test_loss, test_accuracy = evaluate_on_test(model, test_loader, criterion)\n",
    "    results.append({\n",
    "        \"hidden_units\": hidden_units,\n",
    "        \"learning_rate\": learning_rate,\n",
    "        \"train_loss\": train_losses[-1],\n",
    "        \"val_loss\": val_losses[-1],\n",
    "        \"test_loss\": test_loss,\n",
    "        \"train_acc\": train_accuracies[-1],\n",
    "        \"val_acc\": val_accuracies[-1],\n",
    "        \"test_acc\": test_accuracy\n",
    "    })\n",
    "    import matplotlib.pyplot as plt\n",
    "\n",
    "    fig, ax = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "    # Plotting training and validation accuracy\n",
    "    ax[0].plot(train_accuracies)\n",
    "    ax[0].plot(val_accuracies)\n",
    "    ax[0].set_title('Model Accuracy')\n",
    "    ax[0].set_xlabel('Epochs')\n",
    "    ax[0].set_ylabel('Accuracy')\n",
    "    ax[0].legend(['Train', 'Val'])\n",
    "\n",
    "    # Plotting training and validation loss\n",
    "    ax[1].plot(train_losses)\n",
    "    ax[1].plot(val_losses)\n",
    "    ax[1].set_title('Model Loss')\n",
    "    ax[1].set_xlabel('Epochs')\n",
    "    ax[1].set_ylabel('Loss')\n",
    "    ax[1].legend(['Train', 'Val'])\n",
    "\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25",
   "metadata": {
    "id": "a7984c6e-6652-4160-b572-07d48bc93a3f"
   },
   "source": [
    "#### Visualizing the model performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 432
    },
    "id": "5559d850-1fb5-4b04-b6ca-60c5b309f34e",
    "outputId": "d06d3bca-088e-48b1-c91e-3b6161691240"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, ax = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "# Plotting training and validation accuracy\n",
    "ax[0].plot(train_accuracies)\n",
    "ax[0].plot(val_accuracies)\n",
    "ax[0].set_title('Model Accuracy')\n",
    "ax[0].set_xlabel('Epochs')\n",
    "ax[0].set_ylabel('Accuracy')\n",
    "ax[0].legend(['Train', 'Val'])\n",
    "\n",
    "# Plotting training and validation loss\n",
    "ax[1].plot(train_losses)\n",
    "ax[1].plot(val_losses)\n",
    "ax[1].set_title('Model Loss')\n",
    "ax[1].set_xlabel('Epochs')\n",
    "ax[1].set_ylabel('Loss')\n",
    "ax[1].legend(['Train', 'Val'])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 331
    },
    "id": "vyDWTQYT4TO5",
    "outputId": "83aefa4f-f7bc-464d-88c9-3abdd77c3576"
   },
   "outputs": [],
   "source": [
    "# Question 1\n",
    "df_results = pd.DataFrame(results)\n",
    "#df_results = df_results.round(2)\n",
    "df_results.to_csv(\"hyperparameter_results.csv\", index=False)\n",
    "df_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 331
    },
    "id": "JyKWUoSW4nu3",
    "outputId": "08a7cfcf-6246-4afa-b296-aa4196532653"
   },
   "outputs": [],
   "source": [
    "df_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 607
    },
    "id": "004TeDIFGuKy",
    "outputId": "4462c6d6-6332-43a8-a714-3bd055e83947"
   },
   "outputs": [],
   "source": [
    "# Question 2\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "for lr in sorted(df_results['learning_rate'].unique()):\n",
    "    subset = df_results[df_results['learning_rate'] == lr]\n",
    "    plt.plot(subset['hidden_units'], subset['test_acc'], marker='o', label=f\"LR = {lr}\")\n",
    "\n",
    "plt.title(\"Test Accuracy vs Hidden Units (Grouped by Learning Rate)\")\n",
    "plt.xlabel(\"Hidden Units\")\n",
    "plt.ylabel(\"Test Accuracy (%)\")\n",
    "plt.legend(title=\"Learning Rate\")\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 564
    },
    "id": "jNGZsZf3I_Vp",
    "outputId": "30b08fa3-4001-4854-9c19-67386e8c403f"
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "pivot_table = df_results.pivot(index='hidden_units', columns='learning_rate', values='test_acc')\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(pivot_table, annot=True, fmt=\".2f\", cmap=\"YlGnBu\")\n",
    "plt.title(\"Test Accuracy Heatmap\")\n",
    "plt.xlabel(\"Learning Rate\")\n",
    "plt.ylabel(\"Hidden Units\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

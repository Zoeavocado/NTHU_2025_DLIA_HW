{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Li0bVCTuxc6n"
   },
   "source": [
    "<div align=\"center\">\n",
    "\n",
    "#### Lab 3\n",
    "\n",
    "# National Tsing Hua University\n",
    "\n",
    "#### Spring 2025\n",
    "\n",
    "#### 11320IEEM 513600\n",
    "\n",
    "#### Deep Learning and Industrial Applications\n",
    "    \n",
    "## Lab 3: Anomaly Detection in Industrial Applications\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OlvflhYwCu8Q"
   },
   "source": [
    "### Introduction\n",
    "\n",
    "In today's industrial landscape, the ability to detect anomalies in manufacturing processes and products is critical for maintaining quality, efficiency, and safety. This lab focuses on leveraging deep learning techniques for anomaly detection in various industrial applications, using the MVTEC Anomaly Detection Dataset. By employing ImageNet-pretrained models available in torchvision, students will gain hands-on experience in classfying defects and irregularities across different types of industrial products.\n",
    "\n",
    "Throughout this lab, you'll be involved in the following key activities:\n",
    "- Explore and process the MVTec Anomaly Detection Dataset.\n",
    "- Apply ImageNet-pretrained models from [Torchvision](https://pytorch.org/vision/stable/models.html) to detect anomalies in industrial products.\n",
    "- Evaluate the performance of the models to understand their effectiveness in real-world industrial applications.\n",
    "\n",
    "### Objectives\n",
    "\n",
    "- Understand the principles of anomaly detection in the context of industrial applications.\n",
    "- Learn how to implement and utilize ImageNet-pretrained models for detecting anomalies.\n",
    "- Analyze and interpret the results of the anomaly detection models to assess their practicality in industrial settings.\n",
    "\n",
    "### Dataset\n",
    "\n",
    "The MVTec AD Dataset is a comprehensive collection of high-resolution images across different categories of industrial products, such as bottles, cables, and metal nuts, each with various types of defects. This dataset is pivotal for developing and benchmarking anomaly detection algorithms. You can download our lab's dataset [here](https://drive.google.com/file/d/19600hUOpx0hl78TdpdH0oyy-gGTk_F_o/view?usp=share_link). You can drop downloaded data and drop to colab, or you can put into yor google drive.\n",
    "\n",
    "### References\n",
    "- [MVTec AD Dataset](https://www.kaggle.com/datasets/ipythonx/mvtec-ad/data) for the dataset used in this lab.\n",
    "- [Torchvision Models](https://pytorch.org/vision/stable/models.html) for accessing ImageNet-pretrained models to be used in anomaly detection tasks.\n",
    "- [State-of-the-Art Anomaly Detection on MVTec AD](https://paperswithcode.com/sota/anomaly-detection-on-mvtec-ad) for insights into the latest benchmarks and methodologies in anomaly detection applied to the MVTec AD dataset.\n",
    "- [CVPR 2019: MVTec AD — A Comprehensive Real-World Dataset for Unsupervised Anomaly Detection] for the original paper of MVTec AD dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GuiEw1L0Cu8Q"
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "from tqdm.auto import tqdm\n",
    "import cv2\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "from collections import defaultdict\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WBnK4LKIdDR2",
    "outputId": "3fc716af-4a21-4676-994b-2055f92201fd"
   },
   "outputs": [],
   "source": [
    "!unzip \"transistor.zip\" -d \"transistor\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eq48cUqWacMI",
    "outputId": "0ad9a9e6-8200-4dc7-c733-87caf0d78ce5"
   },
   "outputs": [],
   "source": [
    "base_path = '/content/transistor/transistor'\n",
    "file_paths = glob.glob(f'{base_path}/train/good/*.png') + glob.glob(f'{base_path}/test/*/*.png')\n",
    "\n",
    "print(f\"{len(file_paths)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "P55qhaaebAdN"
   },
   "outputs": [],
   "source": [
    "class_names = ['good', 'bent_lead', 'cut_lead', 'damaged_case', 'misplaced']\n",
    "label_map = {name: i for i, name in enumerate(class_names)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 49,
     "referenced_widgets": [
      "c24b85dcbad040af812a873f2931a1da",
      "f5d9e4b23f8943ee94043dadf0259e17",
      "902832555dfb4fdd895312d953a978d9",
      "94232ee3329c48c2b232cb0dbd145240",
      "86b5bcc6a5db43708fbd7a09272a7ebe",
      "e93fc6b4ef2b42609ee11a3c543415fc",
      "812868f5980348c493be829214084a63",
      "440f4efcfc654033b3e02783119c0b7d",
      "8d865dfe1a624be5838f14f40e02b971",
      "ae13aabab2894fe1b0502e1a84c1a975",
      "468aacfc5c264c0792e30095f778088d"
     ]
    },
    "id": "QzUD7MbdbVg3",
    "outputId": "3af9bb31-306a-4a97-d346-4349e9db396a"
   },
   "outputs": [],
   "source": [
    "class_data = defaultdict(list)\n",
    "target_size = (256, 256)\n",
    "\n",
    "for path in tqdm(file_paths):\n",
    "    img = cv2.imread(path)\n",
    "    if img is None:\n",
    "        continue\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    img = cv2.resize(img, target_size)\n",
    "\n",
    "    if 'train' in path:\n",
    "        class_name = 'good'\n",
    "    else:\n",
    "        class_name = path.split('/')[-2]\n",
    "\n",
    "    if class_name in class_names:\n",
    "        class_data[class_name].append(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RJowI5iobxZ4",
    "outputId": "e682d6f8-e804-416c-f7e8-2aa14803aa3b"
   },
   "outputs": [],
   "source": [
    "x_train, y_train, x_val, y_val = [], [], [], []\n",
    "train_ratio = 0.8\n",
    "\n",
    "for class_name in class_names:\n",
    "    imgs = class_data[class_name]\n",
    "    n = len(imgs)\n",
    "    split = int(n * train_ratio)\n",
    "\n",
    "    x_train.extend(imgs[:split])\n",
    "    y_train.extend([label_map[class_name]] * split)\n",
    "\n",
    "    x_val.extend(imgs[split:])\n",
    "    y_val.extend([label_map[class_name]] * (n - split))\n",
    "\n",
    "    print(f\"{class_name}：共 {n} 張圖，訓練 {split}，驗證 {n - split}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "22LfVcCUbxLZ",
    "outputId": "39fcb7d3-b1f3-45c6-c669-0f28e80eb389"
   },
   "outputs": [],
   "source": [
    "x_train = np.transpose(np.array(x_train), (0, 3, 1, 2))\n",
    "x_val = np.transpose(np.array(x_val), (0, 3, 1, 2))\n",
    "y_train = np.array(y_train)\n",
    "y_val = np.array(y_val)\n",
    "\n",
    "print(f\"\\nx_train: {x_train.shape}, y_train: {y_train.shape}\")\n",
    "print(f\"x_val:   {x_val.shape}, y_val:   {y_val.shape}\")\n",
    "print(f\"{label_map}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ii8LH8s4Cu8S"
   },
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "# import numpy as np\n",
    "\n",
    "# classes = sorted(set([path.split('/')[4] for path in file_paths]))\n",
    "# print(f'Classes: {classes}')\n",
    "\n",
    "# images_per_class = len(all_data) // len(classes)\n",
    "# fig, axs = plt.subplots(len(classes), 2, figsize=(6, 4 * len(classes)))\n",
    "\n",
    "# for i, class_name in enumerate(classes):\n",
    "#     index = i * images_per_class\n",
    "#     for j in range(2):\n",
    "#         axs[i, j].set_title(f'{i}. {class_name}')\n",
    "#         axs[i, j].imshow(all_data[index + j])\n",
    "#         axs[i, j].axis('off')\n",
    "\n",
    "# plt.tight_layout() # 自動調整子圖間距\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "w-1PsC--M7pT"
   },
   "source": [
    "## A. Data Loading and Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "h-CnfsmbCu8T"
   },
   "outputs": [],
   "source": [
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from PIL import Image\n",
    "\n",
    "train_transforms = transforms.Compose(\n",
    "    [\n",
    "        transforms.Resize((32, 32)),\n",
    "        transforms.AutoAugment(),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.RandomRotation(15), #attempt 1\n",
    "        transforms.ToTensor(), # 轉為 PyTorch Tensor，值域變成 [0, 1]\n",
    "    ]\n",
    ")\n",
    "\n",
    "val_transforms = transforms.Compose(\n",
    "    [\n",
    "        transforms.Resize((32, 32)),\n",
    "        transforms.ToTensor(),\n",
    "    ]\n",
    ")\n",
    "\n",
    "class MyDataset(Dataset):\n",
    "    def __init__(self, x, y, transform=None):\n",
    "        self.x = x  # x 是圖片資料，shape 通常為 (N, 3, H, W)\n",
    "        self.y = torch.from_numpy(y).long() # y 是 label，轉為 PyTorch tensor\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.x) # 讓 PyTorch 知道有幾筆資料\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        new_x = np.transpose(self.x[idx], (1, 2, 0)) # 將 NumPy 圖片轉成 PIL 圖像 (C, H, W) ➜ (H, W, C)，符合 PIL 需求\n",
    "        return self.transform(Image.fromarray(new_x)), self.y[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "53ZVFFacCu8T"
   },
   "outputs": [],
   "source": [
    "# 用 PyTorch 的 DataLoader 將定義好的 MyDataset 包成可訓練用的批次資料載入器\n",
    "batch_size = 32\n",
    "\n",
    "train_dataset = MyDataset(x_train, y_train, train_transforms)\n",
    "val_dataset = MyDataset(x_val, y_val, val_transforms)\n",
    "\n",
    "# 每次提供訓練資料 batch 給模型\n",
    "# num_workers 用2條平行處理程序來加速讀資料\n",
    "# pin_memory 資料固定在 RAM，GPU 輸入更快\n",
    "# persistent_workers 多輪 epoch 間保留 worker 不關閉\n",
    "train_loader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True, num_workers=2, pin_memory=True, persistent_workers=True)\n",
    "val_loader = DataLoader(dataset=val_dataset, batch_size=batch_size, shuffle=False, num_workers=1, pin_memory=True, persistent_workers=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oaLGtT28xc6s"
   },
   "source": [
    "## B. Defining Neural Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oDX8iDKJCu8U",
    "outputId": "14fada01-20c4-492c-da06-a6eef02cee23"
   },
   "outputs": [],
   "source": [
    "# ResNet-18 預訓練模型，不更新參數，只訓練最後一層來做 8 類分類任務\n",
    "# Transfer Learning\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import models\n",
    "\n",
    "# model = models.resnet18(weights='IMAGENET1K_V1') #使用ImageNet上訓練好的權重（IMAGENET1K_V1）原本的最後一層分類是1000類（ImageNet的類別數）\n",
    "\n",
    "# # ConvNet as fixed feature extractor (freeze parameters)\n",
    "# # 只會訓練自己加上去的最後一層，把 ResNet 當作固定的特徵提取器\n",
    "# for param in model.parameters():\n",
    "#     param.requires_grad = False\n",
    "##################################################### attempt 2\n",
    "model = models.resnet50(weights='IMAGENET1K_V1')\n",
    "for name, param in model.named_parameters():\n",
    "    if 'layer4' in name or 'fc' in name:\n",
    "        param.requires_grad = True\n",
    "    else:\n",
    "        param.requires_grad = False\n",
    "#####################################################\n",
    "# 把最後一層換掉（改成8類輸出）\n",
    "num_ftrs = model.fc.in_features\n",
    "num_class = 5\n",
    "\n",
    "# change # of class from 1000 into 5 in the last layer\n",
    "model.fc = nn.Linear(num_ftrs, num_class)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nvLTU-IfZLqn"
   },
   "source": [
    "## C. Training the Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 937,
     "referenced_widgets": [
      "8d0380efe2334151ac642bf6b75d5c0f",
      "66584b79fa754d518b58b9f1ff62e0a9",
      "7c63bd5a4b924612836a8a4d623f0ecd",
      "c0661bb32bb04052a8db727681a7ec3f",
      "72493468510d44648b7b32986da0b42e",
      "3919eacc595f44d7bd5dbfd354ec025b",
      "0cb99c09cd364f3794e03807a5d21966",
      "36155d3310704bc790405b157f23efb4",
      "56f11b7ffbb44be6a3b804a3bf7fa254",
      "21a9e35638a7490b9fd9414f8162c2c8",
      "e360812db9914cfe803d00b158cba2c9"
     ]
    },
    "id": "45ol4lpVxc6t",
    "outputId": "10af87a2-bb4b-4f95-b8ce-59eb40c5439a"
   },
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR, StepLR\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "train_accuracies = []\n",
    "val_accuracies = []\n",
    "\n",
    "epochs = 50\n",
    "model = model.cuda() # 把模型搬到GPU\n",
    "\n",
    "best_val_loss = float('inf')\n",
    "best_val_acc = -1\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "# optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "# lr_scheduler = CosineAnnealingLR(optimizer, T_max=len(train_loader)*epochs, eta_min=0)\n",
    "################attempt 3\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-4, weight_decay=1e-4)\n",
    "lr_scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=50)\n",
    "################\n",
    "\n",
    "for epoch in tqdm(range(epochs)):\n",
    "    # Training\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "    train_correct = 0\n",
    "    total_train_samples = 0\n",
    "\n",
    "    for images, labels in train_loader:\n",
    "        images = images.cuda()\n",
    "        #images = (images) / 255. #正規化\n",
    "        labels = labels.cuda()\n",
    "        optimizer.zero_grad() #清空梯度\n",
    "        outputs = model(images) #前向傳播\n",
    "\n",
    "        labels = labels.long()\n",
    "\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward() #反向傳播\n",
    "        optimizer.step() #更新參數\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        train_predicted = outputs.argmax(-1) #預測結果\n",
    "        train_correct += (train_predicted == labels).sum().item()\n",
    "        total_train_samples += labels.size(0)\n",
    "\n",
    "    avg_train_loss = total_loss / len(train_loader)\n",
    "    train_accuracy = 100. * train_correct / total_train_samples\n",
    "\n",
    "    # Validation\n",
    "    model.eval()\n",
    "    total_val_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad(): # 驗證不需要梯度，沒有 backward 和 optimizer\n",
    "        for images, labels in val_loader:\n",
    "            images = images.cuda()\n",
    "            #images = (images) / 255.\n",
    "            labels = labels.cuda()\n",
    "            outputs = model(images)\n",
    "\n",
    "            labels = labels.long()\n",
    "\n",
    "            loss = criterion(outputs, labels)\n",
    "            total_val_loss += loss.item()\n",
    "\n",
    "            predicted = outputs.argmax(-1)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "\n",
    "    avg_val_loss = total_val_loss / len(val_loader)\n",
    "    val_accuracy = 100. * correct / total\n",
    "\n",
    "    # Learning rate update 每個epoch結束後更新學習率\n",
    "    lr_scheduler.step()\n",
    "\n",
    "    # Checkpoint\n",
    "    if avg_val_loss < best_val_loss:\n",
    "        best_val_loss = avg_val_loss\n",
    "\n",
    "    if val_accuracy > best_val_acc:\n",
    "        best_val_acc = val_accuracy\n",
    "        torch.save(model.state_dict(), 'model_classification.pth')\n",
    "\n",
    "    print(f'Epoch {epoch+1}/{epochs}, Train loss: {avg_train_loss:.4f}, Train acc: {train_accuracy:.4f}%, Val loss: {avg_val_loss:.4f}, Val acc: {val_accuracy:.4f}%, Best Val loss: {best_val_loss:.4f} Best Val acc: {best_val_acc:.2f}%')\n",
    "\n",
    "    # Store performance\n",
    "    train_losses.append(avg_train_loss)\n",
    "    train_accuracies.append(train_accuracy)\n",
    "    val_losses.append(avg_val_loss)\n",
    "    val_accuracies.append(val_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pjmYxAJnxc6t"
   },
   "source": [
    "### Visualizing model performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 344
    },
    "id": "pHpS0Q7vxc6t",
    "outputId": "139b878a-02fd-4041-c322-c78cf3f77939"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, ax = plt.subplots(1, 2, figsize=(15, 5)) #1列2行\n",
    "\n",
    "# ax[0] 第一張圖（畫準確率）\n",
    "# Plotting training and validation accuracy\n",
    "ax[0].plot(train_accuracies)\n",
    "ax[0].plot(val_accuracies)\n",
    "ax[0].set_title('Model Accuracy')\n",
    "ax[0].set_xlabel('Epochs')\n",
    "ax[0].set_ylabel('Accuracy')\n",
    "ax[0].legend(['Train', 'Val'])\n",
    "\n",
    "# ax[1] 第二張圖（畫損失）\n",
    "# Plotting training and validation loss\n",
    "ax[1].plot(train_losses)\n",
    "ax[1].plot(val_losses)\n",
    "ax[1].set_title('Model Loss')\n",
    "ax[1].set_xlabel('Epochs')\n",
    "ax[1].set_ylabel('Loss')\n",
    "ax[1].legend(['Train', 'Val'])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WVDWBwv6Cu8V"
   },
   "source": [
    "## D. Evaluating Your Trained Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uEztHBDjCu8V"
   },
   "source": [
    "### Load Trained Model and Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2DA1qHXpCu8V",
    "outputId": "a5c8be38-2b2a-4006-8bd9-c459df8bbbb7"
   },
   "outputs": [],
   "source": [
    "# Load the trained weights\n",
    "model.load_state_dict(torch.load('model_classification.pth'))\n",
    "\n",
    "# Set the model to evaluation mode\n",
    "model.eval()\n",
    "\n",
    "test_correct = 0\n",
    "test_total = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, labels in val_loader:\n",
    "\n",
    "        images = images.cuda()\n",
    "        #images = (images) / 255.\n",
    "\n",
    "        labels = labels.cuda()\n",
    "        labels = labels.long()\n",
    "\n",
    "        outputs = model(images) # 模型預測 logits\n",
    "\n",
    "        predicted = outputs.argmax(-1) # 取最大值所在位置（類別）\n",
    "        print(predicted)\n",
    "        print(labels)\n",
    "        test_correct += (predicted == labels).sum().item()\n",
    "        test_total += labels.size(0)\n",
    "\n",
    "print(f'Test accuracy is {100. * test_correct / test_total}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jG6DuAgcEgxj"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
